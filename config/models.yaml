models:
  test-model-a:
    backend: vllm
    backend_url: "http://localhost:8001"
    headers:
      x-test: "1"
    limits:
      max_tokens: 1000
  test-model-b:
    backend: vllm
    backend_url: "http://localhost:8003"
    headers:
      x-test: "1"
    limits:
      max_tokens: 1000
  embedding-model:
    backend: llamacpp
    backend_url: "http://localhost:8002"
    embeddings: true
